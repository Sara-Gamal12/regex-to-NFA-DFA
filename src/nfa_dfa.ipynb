{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wCgGddu0aq8Z"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import deque\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbcI1ewPg4R2"
      },
      "source": [
        "## NFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21Sj5mZDgUcI"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "import json\n",
        "precedence={\n",
        "    \"*\": 6,\n",
        "    \"+\": 5,\n",
        "    \"?\": 4,\n",
        "    \".\": 3,\n",
        "    \"&\": 2,\n",
        "    \"|\": 1,\n",
        "    \"(\": 0,\n",
        "   }\n",
        "@dataclass\n",
        "class State:\n",
        "    index: int = 0\n",
        "    def __post_init__(self):\n",
        "        self.index = State._generate_index()\n",
        "    @staticmethod\n",
        "    def _generate_index():\n",
        "        if not hasattr(State, \"_index_counter\"):\n",
        "            State._index_counter = 0\n",
        "        index = State._index_counter\n",
        "        State._index_counter += 1\n",
        "        return index\n",
        "    pass\n",
        "    @staticmethod\n",
        "    def reset_index_counter():\n",
        "        State._index_counter = 0\n",
        "    pass\n",
        "@dataclass  \n",
        "class Edge:\n",
        "        from_:State\n",
        "        to:State\n",
        "        label:str\n",
        "\n",
        "@dataclass\n",
        "class NFA_node:\n",
        "    start:int\n",
        "    end:int\n",
        "    edges:list[Edge]\n",
        "    states:list[int]\n",
        "\n",
        "     \n",
        "class NFA:\n",
        "    def __init__(self, regex):\n",
        "        try:\n",
        "            State.reset_index_counter()\n",
        "            if not self.is_valid_regex(regex):\n",
        "                raise ValueError(\"Invalid regex\")\n",
        "        except Exception as e:\n",
        "                print(e)\n",
        "                return\n",
        "\n",
        "        tokens=self.tokenize(regex)\n",
        "        tokens=self.handle_dot(tokens) #handle the dot operator\n",
        "        tokens=self.add_concatenation(tokens) #& operator\n",
        "        \n",
        "        postfix=self.regex_to_postfix(tokens)\n",
        "        print(postfix)\n",
        "        nfa=self.build_nfa(postfix)\n",
        "        nfa_json=self.construct_json(nfa)\n",
        "        draw(nfa_json,\"nfa_graph\")\n",
        "    def handle_dot(self,tokens):\n",
        "        \"\"\"\n",
        "        Handle the dot operator in the regex\n",
        "        \"\"\"\n",
        "        new_tokens=[]\n",
        "        i=0\n",
        "        string=\"[a-zA-Z0-9]\"\n",
        "        while i < len(tokens):\n",
        "            token=tokens[i]\n",
        "            if token==\".\":\n",
        "                for char in string:\n",
        "                    new_tokens.append(char)\n",
        "            else:\n",
        "                new_tokens.append(token)\n",
        "            i+=1\n",
        "        return new_tokens\n",
        "    \n",
        "    def construct_json(self,nfa):\n",
        "        nfa_json={}\n",
        "        nfa_json[\"startingState\"] = \"S\"+str(nfa.start.index)\n",
        "        for state in nfa.states:\n",
        "            nfa_json[\"S\"+str(state.index)]={}\n",
        "            nfa_json[\"S\"+str(state.index)][\"isTerminatingState\"]=state==nfa.end\n",
        "\n",
        "        for edge in nfa.edges:\n",
        "            edge_from=edge.from_\n",
        "            edge_to=edge.to\n",
        "            if edge.label==\"epsilon\":\n",
        "                edge.label=\"ε\"\n",
        "            if  not edge.label in nfa_json[\"S\"+str(edge_from.index)] :\n",
        "                nfa_json[\"S\"+str(edge_from.index)][edge.label]=[\"S\"+str(edge_to.index)]\n",
        "            else:\n",
        "                nfa_json[\"S\"+str(edge_from.index)][edge.label].append(\"S\"+str(edge_to.index))\n",
        "\n",
        "        ##save the nfa to a json file\n",
        "        with open(\"nfa.json\",\"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(nfa_json,file,indent=4, ensure_ascii=False)\n",
        "        return nfa_json\n",
        "    def build_nfa(self, postfix):\n",
        "        stack=[]\n",
        "        for token in postfix:\n",
        "            if token.isalnum():\n",
        "               \n",
        "                stack.append(self.construct_nfa( token))\n",
        "            elif token==\"*\":\n",
        "                stack.append(self.kleene_closure(stack.pop()))\n",
        "            elif token==\"+\":\n",
        "                stack.append(self.positive_closure(stack.pop()))\n",
        "            elif token==\"?\":\n",
        "                stack.append(self.zero_or_one(stack.pop()))\n",
        "          \n",
        "            elif token==\"&\":\n",
        "                nfa2=stack.pop()\n",
        "                nfa1=stack.pop()\n",
        "                stack.append(self.concatenation(nfa1,nfa2))\n",
        "            elif token==\"|\":\n",
        "                nfa2=stack.pop()    \n",
        "                nfa1=stack.pop()\n",
        "                stack.append(self.union(nfa1,nfa2))\n",
        "        nfa=stack.pop()\n",
        "        return nfa\n",
        "    def construct_nfa(self, char):\n",
        "       \n",
        "        start=State()\n",
        "        end=State() \n",
        "        edge=Edge(start,end,char)\n",
        "        states=[start,end]\n",
        "        nfa= NFA_node(start,end,[edge],states)\n",
        "        return nfa\n",
        "    def concatenation(self, nfa1, nfa2):\n",
        "        nfa1.states.extend(nfa2.states)\n",
        "        nfa1.edges.extend(nfa2.edges)\n",
        "        nfa1.edges.append(Edge(nfa1.end, nfa2.start, \"epsilon\"))\n",
        "       \n",
        "        nfa1.end = nfa2.end\n",
        "        return nfa1\n",
        "    def union(self, nfa1, nfa2):\n",
        "        start = State()\n",
        "        end = State()\n",
        "        nfa1.states.extend(nfa2.states)\n",
        "        nfa1.states.append(end)\n",
        "        nfa1.states.append(start)\n",
        "        nfa1.edges.extend(nfa2.edges)\n",
        "\n",
        "        nfa1.edges.append(Edge(start,nfa1.start, \"epsilon\"))\n",
        "        nfa1.edges.append(Edge(start,nfa2.start, \"epsilon\"))\n",
        "        nfa1.edges.append(Edge(nfa1.end,end, \"epsilon\"))\n",
        "        nfa1.edges.append(Edge(nfa2.end,end, \"epsilon\"))\n",
        "        nfa1.start=start\n",
        "        \n",
        "        nfa1.end=end\n",
        "        return nfa1\n",
        "       \n",
        "    def kleene_closure(self, nfa):\n",
        "        start = State()\n",
        "        end = State()\n",
        "        nfa.edges.append(Edge(start, nfa.start, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(start, end, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(nfa.end, end, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(nfa.end, start, \"epsilon\"))\n",
        "        nfa.states.extend([start, end])\n",
        "        nfa.start = start\n",
        "        nfa.end = end\n",
        "        return nfa\n",
        "    def zero_or_one(self, nfa):\n",
        "        start = State()\n",
        "        end = State()\n",
        "        nfa.edges.append(Edge(start, nfa.start, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(start, end, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(nfa.end, end, \"epsilon\"))\n",
        "        nfa.states.extend([start, end])\n",
        "        nfa.start = start\n",
        "        nfa.end = end\n",
        "        return nfa\n",
        "    def positive_closure(self, nfa):\n",
        "        start = State()\n",
        "        end = State()   \n",
        "        nfa.states.extend([start, end])\n",
        "    \n",
        "\n",
        "        nfa.edges.append(Edge(start, nfa.start, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(nfa.end, start, \"epsilon\"))\n",
        "        nfa.edges.append(Edge(nfa.end, end, \"epsilon\"))\n",
        "        nfa.start = start\n",
        "        nfa.end = end\n",
        "        return nfa\n",
        "\n",
        "  \n",
        "\n",
        "    def add_concatenation(self,tokens):\n",
        "        new_tokens=[]\n",
        "        i=0\n",
        "        while i<len(tokens):\n",
        "            token=tokens[i]\n",
        "            if token==\"[\":\n",
        "                ##skip till ]\n",
        "                while i<len(tokens) and tokens[i]!=\"]\":\n",
        "                    new_tokens.append(tokens[i])\n",
        "                    i+=1\n",
        "                continue\n",
        "            new_tokens.append(token)\n",
        "            if token.isalnum() or token in \")]?+.*\": #add concatenation operator\n",
        "                if i+1<len(tokens) and (tokens[i+1].isalnum() or tokens[i+1]==\"(\" or tokens[i+1]==\"[\"):\n",
        "                    new_tokens.append(\"&\")\n",
        "            i+=1\n",
        "        return new_tokens\n",
        "\n",
        "    def is_valid_regex(self,regex):\n",
        "        stack = []\n",
        "        prev_char = None\n",
        "        escaped=False\n",
        "        bracket_content = \"\"\n",
        "        in_bracket = False\n",
        "\n",
        "\n",
        "        for i, char in enumerate(regex):\n",
        "            ##check that char belongs to the valid set of characters\n",
        "            if not char.isalnum() and char not in \".-()|*+?[]\\\\\":\n",
        "                return False\n",
        "            if escaped:  \n",
        "                # Allow any character after `\\` (like `\\[` or `\\+`)\n",
        "                escaped = False  \n",
        "                continue  \n",
        "            if char == '(':\n",
        "                stack.append('(')\n",
        "            elif char == ')':\n",
        "                if prev_char in \"(|\":\n",
        "                    return False\n",
        "                if not stack or stack[-1] != '(':\n",
        "                    return False\n",
        "                stack.pop()\n",
        "            elif char == '[':\n",
        "                if (in_bracket):\n",
        "                    return False\n",
        "                in_bracket = True\n",
        "                bracket_content = \"\"\n",
        "                stack.append('[')\n",
        "            elif char == ']':\n",
        "                if not stack or stack[-1] != '[':\n",
        "                    return False\n",
        "                if not self.valid_range(bracket_content):\n",
        "                    return False\n",
        "                in_bracket = False\n",
        "\n",
        "                stack.pop()\n",
        "            elif in_bracket:\n",
        "                bracket_content += char\n",
        "            elif char==\"-\":\n",
        "                if not in_bracket or i==0 or i==len(regex)-1 or prev_char in \"[-|\":\n",
        "                    return False\n",
        "            # Ensure `*`, `+`, `?` are not first characters\n",
        "            elif char in \"*+?\" and (i == 0 or prev_char in \"(|\"):\n",
        "                return False\n",
        "\n",
        "            # Ensure `|` is not at start or end\n",
        "            elif char == \"|\" and (i == 0 or i == len(regex) - 1 or regex[i - 1] in \"(|\"):\n",
        "                return False\n",
        "            \n",
        "            # Ensure `\\` is followed by something\n",
        "            elif char == \"\\\\\":\n",
        "                escaped = True\n",
        "                if i == len(regex) - 1:  # Last character cannot be `\\`\n",
        "                    return False\n",
        "            \n",
        "            prev_char = char\n",
        "\n",
        "        # Ensure no unclosed brackets or parentheses\n",
        "        return len(stack) == 0\n",
        "    def valid_range(self, bracket_content):\n",
        "        \"\"\"\n",
        "        Check if the content of a bracket is a valid range\n",
        "        \n",
        "        \"\"\"\n",
        "        if not bracket_content or bracket_content[0] == '-' or bracket_content[-1] == '-':\n",
        "             return False\n",
        "    \n",
        "        parts = bracket_content.split('-')\n",
        "        i = 0\n",
        "        while i < len(bracket_content):\n",
        "            if (not bracket_content[i].isalnum() ):\n",
        "\n",
        "                return False\n",
        "            if i + 2 < len(bracket_content) and bracket_content[i + 1] == '-':\n",
        "                if bracket_content[i] >= bracket_content[i + 2]:\n",
        "                    return False  # Invalid range (e.g., Z-A)\n",
        "                i += 3  # Skip over the range\n",
        "            else:\n",
        "                i += 1  # Move to the next character\n",
        "        \n",
        "        return True\n",
        "\n",
        "\n",
        "    def tokenize(self,regex):\n",
        "        \"\"\"\"\n",
        "        Tokenize the regex string\n",
        "    \n",
        "        \"\"\"\n",
        "        tokens=[]\n",
        "        escaped=False\n",
        "        for i,char in enumerate(regex):\n",
        "            if escaped:\n",
        "                escaped=False\n",
        "                tokens.append(char)\n",
        "                continue\n",
        "            if char==\"\\\\\":\n",
        "                escaped=True\n",
        "                continue\n",
        "\n",
        "            tokens.append(char)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def regex_to_postfix(self,tokens):\n",
        "        \"\"\"\n",
        "        Convert the regex to postfix notation\n",
        "        \n",
        "        \"\"\"\n",
        "        stack=[]\n",
        "        postfix=[]\n",
        "        i =0\n",
        "        while i <  (len(tokens)):\n",
        "            token=tokens[i]\n",
        "            \n",
        "            i+=1\n",
        "            if token.isalnum():\n",
        "                postfix.append(token)\n",
        "            elif token==\"(\":\n",
        "                stack.append(token)\n",
        "            elif token==\")\":\n",
        "                while stack and stack[-1]!=\"(\":\n",
        "                    postfix.append(stack.pop())\n",
        "                stack.pop()\n",
        "            elif token==\"[\":\n",
        "                expanded_chars = []\n",
        "                while i < len(tokens) and tokens[i] != \"]\":\n",
        "                    if i + 2 < len(tokens) and tokens[i + 1] == \"-\":  # Handle ranges like a-c\n",
        "                        start, end = tokens[i], tokens[i + 2]\n",
        "                      \n",
        "                        expanded_chars.extend(chr(j) for j in range(ord(start), ord(end) + 1))\n",
        "                        i += 3  # Skip `start-end`\n",
        "                    else:\n",
        "                        expanded_chars.append(tokens[i])\n",
        "                        i += 1\n",
        "                i += 1\n",
        "                postfix.append(expanded_chars[0])\n",
        "\n",
        "                for char in expanded_chars[1:]:\n",
        "                                postfix.append(char)\n",
        "                                postfix.append(\"|\")  \n",
        "\n",
        "\n",
        "            elif token in \"*+?.\":\n",
        "                postfix.append(token)\n",
        "            elif token in \"&|\":\n",
        "                while stack  and precedence[stack[-1]]>=precedence[token]:\n",
        "                    postfix.append(stack.pop())\n",
        "                stack.append(token)\n",
        "           \n",
        "        while stack:\n",
        "            postfix.append(stack.pop())\n",
        "        return postfix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq2UjOXwg8tv"
      },
      "source": [
        "# NFA to Minimized DFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HtN6mjNnli51"
      },
      "outputs": [],
      "source": [
        "class Minimized_DFA:\n",
        "    def __init__(self, nfa_json):\n",
        "        dfa=self.nfa_to_dfa(nfa_json)\n",
        "        minimized_dfa=self.minimize_dfa(dfa)\n",
        "        with open(\"minimized_dfa.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(minimized_dfa, file, indent=4, ensure_ascii=False)\n",
        "        draw(minimized_dfa,\"minimized_dfa_graph\")\n",
        "\n",
        "\n",
        "    def epsilon_closure(self,nfa,states):\n",
        "        closure = set(states)\n",
        "        queue = deque(states)\n",
        "        while queue:\n",
        "            state = queue.popleft()\n",
        "            if \"ε\" in nfa[state]:\n",
        "                for next_state in nfa[state][\"ε\"]:\n",
        "                    if next_state not in closure:\n",
        "                        closure.add(next_state)\n",
        "                        queue.append(next_state)\n",
        "        return closure\n",
        "\n",
        "    def nfa_to_dfa(self,nfa_json):\n",
        "        with open(nfa_json, \"r\", encoding=\"utf-8\") as file:\n",
        "            nfa = json.load(file)\n",
        "        starting_state = nfa[\"startingState\"]\n",
        "        nfa_states = {state: state_info for state, state_info in nfa.items() if state != \"startingState\"}\n",
        "        inputs= set()\n",
        "        for state, state_info in nfa_states.items():\n",
        "                for input in state_info.keys():\n",
        "                    if input not in (\"ε\", \"isTerminatingState\"):\n",
        "                        inputs.add(input)\n",
        "        dfa = {\"startingState\": \"S0\"}\n",
        "        queue = deque()\n",
        "        start_closure = frozenset(self.epsilon_closure(nfa_states,[starting_state]))\n",
        "        queue.append(start_closure)\n",
        "        dfa_states = {start_closure: \"S0\"}\n",
        "        count = 1\n",
        "\n",
        "        while queue:\n",
        "            current_group = queue.popleft()\n",
        "            current_state = dfa_states[current_group]\n",
        "            dfa[current_state] = {\"isTerminatingState\": any(nfa_states[state][\"isTerminatingState\"] for state in current_group)}\n",
        "\n",
        "            for input in inputs:\n",
        "                new_group = set()\n",
        "                for state in current_group:\n",
        "                    if input in nfa_states[state]:\n",
        "                        for next_state in nfa_states[state][input]:\n",
        "                          new_group.add(next_state)\n",
        "                updated_group=self.epsilon_closure(nfa_states,new_group)\n",
        "                new_group = frozenset(updated_group)\n",
        "                if new_group:\n",
        "                    if new_group not in dfa_states:\n",
        "                        dfa_states[new_group] = f\"S{count}\"\n",
        "                        queue.append(new_group)\n",
        "                        count += 1\n",
        "                    dfa[current_state][input] = dfa_states[new_group]\n",
        "\n",
        "        return dfa\n",
        "\n",
        "    def find_group_index(self,groups, state):\n",
        "        for i, group in enumerate(groups):\n",
        "            if state in group:\n",
        "                return i\n",
        "\n",
        "    def minimize_dfa(self,dfa):\n",
        "        starting_state = dfa[\"startingState\"]\n",
        "        dfa_states = {state: state_info for state, state_info in dfa.items() if state != \"startingState\"}\n",
        "\n",
        "        accepting_states = {state for state, state_info in dfa_states.items() if state_info[\"isTerminatingState\"]}\n",
        "        non_accepting_states = dfa_states.keys() - accepting_states\n",
        "        groups = [accepting_states, non_accepting_states]\n",
        "\n",
        "        changed = True\n",
        "        while changed:\n",
        "            new_groups = []\n",
        "            changed = False\n",
        "            for group in groups:\n",
        "                grouped_by_transitions = {}\n",
        "                for state in group:\n",
        "                    transitions = tuple((input, self.find_group_index(groups, dfa_states[state].get(input))) for input in dfa_states[state] if input != \"isTerminatingState\")\n",
        "                    if transitions not in grouped_by_transitions:\n",
        "                        grouped_by_transitions[transitions] = set()\n",
        "                    grouped_by_transitions[transitions].add(state)\n",
        "\n",
        "                new_groups.extend(grouped_by_transitions.values())\n",
        "                if len(grouped_by_transitions) > 1:\n",
        "                    changed = True\n",
        "\n",
        "            groups = new_groups\n",
        "\n",
        "        state_map = {state: f\"S{i}\" for i, group in enumerate(groups) for state in group}\n",
        "        minimized_dfa = {\"startingState\": state_map[starting_state]}\n",
        "\n",
        "        for group in groups:\n",
        "            representative_state = list(group)[0]\n",
        "            new_state = state_map[representative_state]\n",
        "            minimized_dfa[new_state] = {\"isTerminatingState\": dfa_states[representative_state][\"isTerminatingState\"]}\n",
        "            for input, next_state in dfa_states[representative_state].items():\n",
        "                if input != \"isTerminatingState\":\n",
        "                    minimized_dfa[new_state][input] = state_map[next_state]\n",
        "\n",
        "        return minimized_dfa\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIAi0-S4hSwX"
      },
      "source": [
        "# Visiualizing Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c-RwM5dpgw3r"
      },
      "outputs": [],
      "source": [
        "\n",
        "def draw(json_format, output_file):\n",
        "    dot = graphviz.Digraph(format=\"png\")\n",
        "\n",
        "    # Extract the starting state\n",
        "    start_state = json_format[\"startingState\"]\n",
        "\n",
        "    ##color the starting state\n",
        "    dot.node(start_state, shape=\"circle\", style=\"filled\", fillcolor=\"lightgrey\")\n",
        "    ##add edge to starting state from no where\n",
        "    dot.node(\"\", shape=\"point\")  # Add an invisible starting point\n",
        "    dot.edge(\"\", start_state, label=\"start\")\n",
        "\n",
        "\n",
        "    for state, transitions in json_format.items():\n",
        "        if state == \"startingState\":\n",
        "            continue\n",
        "        # Mark accepting (terminating) states differently\n",
        "        if transitions[\"isTerminatingState\"]:\n",
        "            dot.node(state, shape=\"doublecircle\")\n",
        "        else:\n",
        "            dot.node(state, shape=\"circle\")\n",
        "\n",
        "        if(output_file==\"nfa_graph\"):\n",
        "          # Add transitions\n",
        "          for symbol, target_state in transitions.items():\n",
        "              if symbol != \"isTerminatingState\":  # Avoid unnecessary key\n",
        "                  for target in target_state:\n",
        "                      dot.edge(state, target, label=symbol)\n",
        "        else:\n",
        "          # Add transitions\n",
        "          for symbol, target_state in transitions.items():\n",
        "              if symbol != \"isTerminatingState\":  # Avoid unnecessary key\n",
        "                      dot.edge(state, target_state, label=symbol)\n",
        "\n",
        "\n",
        "\n",
        "    # Render and save the graph\n",
        "    dot.render(output_file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJF41B9Yho6B",
        "outputId": "47ee1917-9ce0-41f2-f7f5-4e6f7b2317ab"
      },
      "outputs": [],
      "source": [
        "def main(regex):\n",
        "    NFA(regex)\n",
        "    Minimized_DFA(\"nfa.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'b', '&', 'c', '&', 'd', '&']\n"
          ]
        }
      ],
      "source": [
        "regex=\"abcd\"\n",
        "main(regex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
